{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/moonsejin315/Python/blob/main/%08openapi_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "6ikYycTY5OaG"
      },
      "outputs": [],
      "source": [
        "import openai\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "openai.api_key = OPENAI_API_KEY"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fine-tuning"
      ],
      "metadata": {
        "id": "yJudPY3yOlVm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IxjZfDqH5kTl",
        "outputId": "239938a3-da97-4b78-e580-aeb446dd6ec2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Upload file id: file-pEa806p6xkY28SEhTW20I1fE\n"
          ]
        }
      ],
      "source": [
        "# Step 1: Upload the dataset\n",
        "response = openai.File.create(\n",
        "    file=open(\"mydata.jsonl\", \"rb\"), #새로운 jsonl파일 오류발생.\n",
        "    purpose='fine-tune'\n",
        ")\n",
        "file_id = response['id']\n",
        "print(f\"Upload file id: {file_id}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "0fqOZUU2DuSd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e5868841-dfd8-4bb7-b4ad-f4f18be161fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tuning job id: ftjob-aTRwfBrHnM45ur918hLm3qvv\n"
          ]
        }
      ],
      "source": [
        "# Step 2 : Create a fine-tuning job\n",
        "response = openai.FineTuningJob.create(\n",
        "    training_file=file_id,\n",
        "    model='gpt-4o-mini-2024-07-18'\n",
        ")\n",
        "fine_tune_id = response['id']\n",
        "print(f\"Fine-tuning job id: {fine_tune_id}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Step 3 : Monitor the fine-tuning job\n",
        "while True:\n",
        "  response = openai.FineTuningJob.retrieve(fine_tune_id)\n",
        "  status = response['status']\n",
        "  if status in ['succeeded', 'failed']:\n",
        "    break\n",
        "  print(f\"Fine-tuning status: {status}\")\n",
        "  time.sleep(60)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RUGlywUyHauG",
        "outputId": "fab8155e-fc4e-49be-e734-b47c54390481"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tuning status: validating_files\n",
            "Fine-tuning status: running\n",
            "Fine-tuning status: running\n",
            "Fine-tuning status: running\n",
            "Fine-tuning status: running\n",
            "Fine-tuning status: running\n",
            "Fine-tuning status: running\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if status == 'succeeded':\n",
        "    # Step 4: Use the fine-tuned model (Chat-based model)\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=response['fine_tuned_model'],  # fine-tuned 모델의 ID\n",
        "        messages=[\n",
        "            {\"role\": \"user\", \"content\": \"Translate the following English text to Spanish: 'Good night'\"}\n",
        "        ],\n",
        "        max_tokens=50\n",
        "    )\n",
        "    print(f\"Fine-tuned model output: {response['choices'][0]['message']['content'].strip()}\")\n",
        "else:\n",
        "    print(\"Fine-tuning failed.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FgfSsVYxcg3H",
        "outputId": "eba8baf2-ce22-4401-be1f-06c8e22bde1b"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tuned model output: 'Buenas noches'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Edit"
      ],
      "metadata": {
        "id": "p8iEQqguQ0Ba"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "\n",
        "def edit_text(input_text, instruction):\n",
        "    # Use gpt-3.5-turbo model via ChatCompletion for text modification\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=\"gpt-3.5-turbo\",  # Use the correct model for editing\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "            {\"role\": \"user\", \"content\": f\"Edit the following text: '{input_text}' based on the instruction: {instruction}\"}\n",
        "        ]\n",
        "    )\n",
        "    return response['choices'][0]['message']['content']\n",
        "\n",
        "# Input and instruction\n",
        "input_text = \"우리 집에 오리가 들어와서 강아지가 놀라서 도망갔어.\"\n",
        "instruction = \"'오리'를 '고양이'로 바꿔줘.\" # 프롬프트 수정하기.\n",
        "\n",
        "# Call the function\n",
        "try:\n",
        "    edited_text = edit_text(input_text, instruction)\n",
        "    print(f\"Edited text: {edited_text}\")\n",
        "except openai.error.OpenAIError as e:\n",
        "    print(f\"An error occurred: {e}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jWnYhCUlQ1Rl",
        "outputId": "3059d06c-be67-4900-f1fa-ee06e1d20a2a"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Edited text: '우리 집에 고양이가 들어와서 강아지가 놀라서 도망갔어.'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Moderation"
      ],
      "metadata": {
        "id": "NwC167i7S9IM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Set your OpenAI API key\n",
        "openai.api_key = OPENAI_API_KEY\n",
        "\n",
        "#Function to moderate text using the Moderation API\n",
        "def moderate_text(text):\n",
        "    response = openai.Moderation.create(input=text, model = \"text-moderation-stable\")\n",
        "    return response\n",
        "\n",
        "#Example input text\n",
        "input_texts = [\"I'm feeling really down and lost.\", \"You are truly wonderful.\", \"How about we meet at 8 PM?\", \"I can't stand you and I feel angry.\"] #input_texts 수정."
      ],
      "metadata": {
        "id": "b2SN3vBoty7e"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Moderate each text and print the results\n",
        "for text in input_texts:\n",
        "  moeration_result = moderate_text(text)\n",
        "  print(f\"Input text: {text}\")\n",
        "  print(f\"Moderation result: {moeration_result}\")\n",
        "  print(\"-\" * 40)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oie5c1yhuXAh",
        "outputId": "b8ffade0-450a-4d48-e643-cc96adcfc5da"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input text: I'm feeling really down and lost.\n",
            "Moderation result: {\n",
            "  \"id\": \"modr-AWGKTSyBAQEWxyajKk0WuFdYi2Nou\",\n",
            "  \"model\": \"text-moderation-007\",\n",
            "  \"results\": [\n",
            "    {\n",
            "      \"flagged\": false,\n",
            "      \"categories\": {\n",
            "        \"sexual\": false,\n",
            "        \"hate\": false,\n",
            "        \"harassment\": false,\n",
            "        \"self-harm\": false,\n",
            "        \"sexual/minors\": false,\n",
            "        \"hate/threatening\": false,\n",
            "        \"violence/graphic\": false,\n",
            "        \"self-harm/intent\": false,\n",
            "        \"self-harm/instructions\": false,\n",
            "        \"harassment/threatening\": false,\n",
            "        \"violence\": false\n",
            "      },\n",
            "      \"category_scores\": {\n",
            "        \"sexual\": 1.497456196375424e-06,\n",
            "        \"hate\": 2.013179482673877e-06,\n",
            "        \"harassment\": 1.2267415741007426e-06,\n",
            "        \"self-harm\": 0.0032760670874267817,\n",
            "        \"sexual/minors\": 5.820779733767267e-07,\n",
            "        \"hate/threatening\": 3.6316057799856694e-11,\n",
            "        \"violence/graphic\": 7.804863457749889e-07,\n",
            "        \"self-harm/intent\": 0.003207447938621044,\n",
            "        \"self-harm/instructions\": 2.0053098737093933e-08,\n",
            "        \"harassment/threatening\": 3.3749153471873683e-10,\n",
            "        \"violence\": 3.5355365071154665e-06\n",
            "      }\n",
            "    }\n",
            "  ]\n",
            "}\n",
            "----------------------------------------\n",
            "Input text: You are truly wonderful.\n",
            "Moderation result: {\n",
            "  \"id\": \"modr-AWGKTjigwN7F4ZOpx3FI6MaLWtV3X\",\n",
            "  \"model\": \"text-moderation-007\",\n",
            "  \"results\": [\n",
            "    {\n",
            "      \"flagged\": false,\n",
            "      \"categories\": {\n",
            "        \"sexual\": false,\n",
            "        \"hate\": false,\n",
            "        \"harassment\": false,\n",
            "        \"self-harm\": false,\n",
            "        \"sexual/minors\": false,\n",
            "        \"hate/threatening\": false,\n",
            "        \"violence/graphic\": false,\n",
            "        \"self-harm/intent\": false,\n",
            "        \"self-harm/instructions\": false,\n",
            "        \"harassment/threatening\": false,\n",
            "        \"violence\": false\n",
            "      },\n",
            "      \"category_scores\": {\n",
            "        \"sexual\": 5.7546898460714146e-05,\n",
            "        \"hate\": 5.276263550513249e-07,\n",
            "        \"harassment\": 0.00047898595221340656,\n",
            "        \"self-harm\": 1.5336985370595357e-06,\n",
            "        \"sexual/minors\": 6.32167484582169e-07,\n",
            "        \"hate/threatening\": 2.6474911152263303e-10,\n",
            "        \"violence/graphic\": 6.241712640076003e-07,\n",
            "        \"self-harm/intent\": 3.2573479984421283e-06,\n",
            "        \"self-harm/instructions\": 2.9130795155651867e-05,\n",
            "        \"harassment/threatening\": 2.317268865681399e-07,\n",
            "        \"violence\": 9.392889296577778e-06\n",
            "      }\n",
            "    }\n",
            "  ]\n",
            "}\n",
            "----------------------------------------\n",
            "Input text: How about we meet at 8 PM?\n",
            "Moderation result: {\n",
            "  \"id\": \"modr-AWGKTOU6whfipD7rAHjRWZj4nbjae\",\n",
            "  \"model\": \"text-moderation-007\",\n",
            "  \"results\": [\n",
            "    {\n",
            "      \"flagged\": false,\n",
            "      \"categories\": {\n",
            "        \"sexual\": false,\n",
            "        \"hate\": false,\n",
            "        \"harassment\": false,\n",
            "        \"self-harm\": false,\n",
            "        \"sexual/minors\": false,\n",
            "        \"hate/threatening\": false,\n",
            "        \"violence/graphic\": false,\n",
            "        \"self-harm/intent\": false,\n",
            "        \"self-harm/instructions\": false,\n",
            "        \"harassment/threatening\": false,\n",
            "        \"violence\": false\n",
            "      },\n",
            "      \"category_scores\": {\n",
            "        \"sexual\": 2.988416781590786e-05,\n",
            "        \"hate\": 7.531051232945174e-05,\n",
            "        \"harassment\": 7.14752241037786e-05,\n",
            "        \"self-harm\": 5.4592869673797395e-06,\n",
            "        \"sexual/minors\": 7.4465897341724485e-06,\n",
            "        \"hate/threatening\": 2.1918825950706378e-05,\n",
            "        \"violence/graphic\": 1.4825212929281406e-05,\n",
            "        \"self-harm/intent\": 1.8249573940920527e-06,\n",
            "        \"self-harm/instructions\": 2.0581305193445587e-07,\n",
            "        \"harassment/threatening\": 0.0004486969264689833,\n",
            "        \"violence\": 0.0004712016088888049\n",
            "      }\n",
            "    }\n",
            "  ]\n",
            "}\n",
            "----------------------------------------\n",
            "Input text: I can't stand you and I feel angry.\n",
            "Moderation result: {\n",
            "  \"id\": \"modr-AWGKTJPZ0msXrlXNgMG4GmvLGtiPT\",\n",
            "  \"model\": \"text-moderation-007\",\n",
            "  \"results\": [\n",
            "    {\n",
            "      \"flagged\": false,\n",
            "      \"categories\": {\n",
            "        \"sexual\": false,\n",
            "        \"hate\": false,\n",
            "        \"harassment\": false,\n",
            "        \"self-harm\": false,\n",
            "        \"sexual/minors\": false,\n",
            "        \"hate/threatening\": false,\n",
            "        \"violence/graphic\": false,\n",
            "        \"self-harm/intent\": false,\n",
            "        \"self-harm/instructions\": false,\n",
            "        \"harassment/threatening\": false,\n",
            "        \"violence\": false\n",
            "      },\n",
            "      \"category_scores\": {\n",
            "        \"sexual\": 3.130955690267001e-07,\n",
            "        \"hate\": 2.1262954760459252e-05,\n",
            "        \"harassment\": 0.07559235394001007,\n",
            "        \"self-harm\": 2.5420041538382065e-07,\n",
            "        \"sexual/minors\": 2.748911320793468e-09,\n",
            "        \"hate/threatening\": 1.9474639678662697e-09,\n",
            "        \"violence/graphic\": 1.2440863201845787e-06,\n",
            "        \"self-harm/intent\": 2.4200513593086725e-08,\n",
            "        \"self-harm/instructions\": 1.4015021365665348e-09,\n",
            "        \"harassment/threatening\": 8.392939889745321e-06,\n",
            "        \"violence\": 0.00048705277731642127\n",
            "      }\n",
            "    }\n",
            "  ]\n",
            "}\n",
            "----------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Image"
      ],
      "metadata": {
        "id": "ZWsKPb91TgoA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "import requests\n",
        "from PIL import Image\n",
        "from io import BytesIO\n",
        "\n",
        "#Set your OpenAI API key\n",
        "openai.api_key = OPENAI_API_KEY\n",
        "\n",
        "def generate_image(prompt):\n",
        "      response = openai.Image.create(\n",
        "          prompt=prompt,\n",
        "          n=1,\n",
        "          size=\"1024x1024\"\n",
        "      )\n",
        "      image_url = response['data'][0]['url']\n",
        "      return image_url\n"
      ],
      "metadata": {
        "id": "se26Sq3HH9MD"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_image(image_url, filename):\n",
        "    response = requests.get(image_url)\n",
        "    img = Image.open(BytesIO(response.content))\n",
        "    img.save(filename)\n",
        "\n",
        "#Example prompt 수정된 내용.\n",
        "prompt = \"Draw me a rabbit walking in the forest. The rabbit's color is white and his face is very cute. His eyes are full of anticipation. The background of the forest is a warm background like plants, butterflies, and bees. The rabbit is walking with a smile while looking around with curiosity. In the back, his friends are walking with him. Also, the rabbit is wearing a bag because it looks like he is going on a picnic, but the bag is a blue bag, which is a little smaller than the rabbit. Also, the design is simple, and there are two small zippers at the front of the bag. The rabbit's friends are walking with a raccoon deer and a fox, not a rabbit. They are also full of expectations on their faces to go on a picnic together and wear pink, yellow, and green bags, respectively. Their atmosphere feels like it will be in a Disney movie. Overall, it creates an image by expressing a bright and bright feeling in a variety of ways\"\n",
        "\n",
        "#Generate image\n",
        "image_url = generate_image(prompt)\n",
        "print(f\"Generated image URL: {image_url}\")\n",
        "\n",
        "#Save image\n",
        "save_image(image_url, \"generated_image.png\")\n",
        "print(\"Image saved as generated_image.png\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cJLkRA2itJOU",
        "outputId": "8a2b1ada-d27c-46f1-a78d-df18a00257fc"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated image URL: https://oaidalleapiprodscus.blob.core.windows.net/private/org-n1KndLeIJu0SHn3KTB2p51hw/user-Tp1u3ZcRJ4y0n2o6L1OMJ3ZF/img-l7YaRDhoRxwiAE0LFQzB9HmD.png?st=2024-11-22T03%3A38%3A25Z&se=2024-11-22T05%3A38%3A25Z&sp=r&sv=2024-08-04&sr=b&rscd=inline&rsct=image/png&skoid=d505667d-d6c1-4a0a-bac7-5c84a87759f8&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2024-11-22T00%3A20%3A24Z&ske=2024-11-23T00%3A20%3A24Z&sks=b&skv=2024-08-04&sig=bsZDIVsFgwgYRT9a7oG8IXQBR3Y4bTKyIpcWn0BkUPI%3D\n",
            "Image saved as generated_image.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Codex"
      ],
      "metadata": {
        "id": "D5iarNgtTl3-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def generate_code(prompt, model='gpt-3.5-turbo', max_tokens=1000):\n",
        "    try:\n",
        "        # Chat 모델에 맞게 messages 형식을 사용\n",
        "        response = openai.ChatCompletion.create(\n",
        "            model=model,\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "                {\"role\": \"user\", \"content\": prompt}\n",
        "            ],\n",
        "            max_tokens=max_tokens,\n",
        "            temperature=0,\n",
        "            n=1,\n",
        "            stop=None\n",
        "        )\n",
        "        # ChatCompletion에서 응답 추출\n",
        "        code = response['choices'][0]['message']['content'].strip()\n",
        "        return code\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {str(e)}\")\n",
        "        return None"
      ],
      "metadata": {
        "id": "vor-zTOgtbU_"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#기존 피보나치 수열을 구현하는 C언어 코딩에서\n",
        "#BFS 알고리즘 코드를 작성하는 Python언어 코딩으로 변경.\n",
        "prompt = \"Please write code for implementing BFS with Python\" #변경된 프롬프트.\n",
        "\n",
        "generated_code = generate_code(prompt)\n",
        "\n",
        "if generated_code:\n",
        "    print(\"Generated Code:\")\n",
        "    print(generated_code)\n",
        "else:\n",
        "    print(\"Code generation failed.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "08M2fFFu4wH5",
        "outputId": "5cd24b11-d0ff-4b27-948a-89eea42c952f"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Code:\n",
            "Sure! Here is an example code for implementing Breadth-First Search (BFS) in Python:\n",
            "\n",
            "```python\n",
            "from collections import deque\n",
            "\n",
            "def bfs(graph, start):\n",
            "    visited = set()\n",
            "    queue = deque([start])\n",
            "    \n",
            "    while queue:\n",
            "        node = queue.popleft()\n",
            "        if node not in visited:\n",
            "            print(node, end=' ')\n",
            "            visited.add(node)\n",
            "            queue.extend(graph[node] - visited)\n",
            "\n",
            "# Example graph as an adjacency list\n",
            "graph = {\n",
            "    'A': {'B', 'C'},\n",
            "    'B': {'A', 'D', 'E'},\n",
            "    'C': {'A', 'F'},\n",
            "    'D': {'B'},\n",
            "    'E': {'B', 'F'},\n",
            "    'F': {'C', 'E'}\n",
            "}\n",
            "\n",
            "# Starting node for BFS\n",
            "start_node = 'A'\n",
            "\n",
            "print(\"BFS traversal starting from node\", start_node, \":\")\n",
            "bfs(graph, start_node)\n",
            "```\n",
            "\n",
            "You can run this code to perform a BFS traversal on the example graph provided. Feel free to modify the graph or starting node as needed for your specific use case.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## File"
      ],
      "metadata": {
        "id": "JPA_qMCRTo2z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "upload_response = openai.File.create(\n",
        "    #새로운 jsonl파일 입력.\n",
        "    file = open(\"product_data.jsonl\", \"rb\"),\n",
        "    purpose = 'fine-tune'\n",
        ")\n",
        "print(\"Upload Response\")\n",
        "print(upload_response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AT_LPfXI5rhr",
        "outputId": "c8da389d-1f2e-44f6-9f5b-b509ea3d441e"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Upload Response\n",
            "{\n",
            "  \"object\": \"file\",\n",
            "  \"id\": \"file-Xt0Jf7UuRLAv0w6U8jzNSQRP\",\n",
            "  \"purpose\": \"fine-tune\",\n",
            "  \"filename\": \"file\",\n",
            "  \"bytes\": 251,\n",
            "  \"created_at\": 1732252732,\n",
            "  \"status\": \"processed\",\n",
            "  \"status_details\": null\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#List all files\n",
        "list_response = openai.File.list()\n",
        "print(\"List Response\")\n",
        "print(list_response)\n",
        "\n",
        "#Retrieve a specific file\n",
        "file_id = upload_response['id']\n",
        "retrieve_response = openai.File.retrieve(file_id)\n",
        "print(\"Retrieve Response\")\n",
        "print(retrieve_response)\n",
        "\n",
        "#Delete a file\n",
        "delete_response = openai.File.delete(file_id)\n",
        "print(\"Delete Response\")\n",
        "print(delete_response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ym1f4AeF57za",
        "outputId": "dea3ca7d-c1e6-47a2-a5a8-92627cb39653"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "List Response\n",
            "{\n",
            "  \"object\": \"list\",\n",
            "  \"data\": [\n",
            "    {\n",
            "      \"object\": \"file\",\n",
            "      \"id\": \"file-Xt0Jf7UuRLAv0w6U8jzNSQRP\",\n",
            "      \"purpose\": \"fine-tune\",\n",
            "      \"filename\": \"file\",\n",
            "      \"bytes\": 251,\n",
            "      \"created_at\": 1732252732,\n",
            "      \"status\": \"processed\",\n",
            "      \"status_details\": null\n",
            "    },\n",
            "    {\n",
            "      \"object\": \"file\",\n",
            "      \"id\": \"file-jLMTp77tUPmTNwjHBeGHbYTz\",\n",
            "      \"purpose\": \"fine-tune\",\n",
            "      \"filename\": \"file\",\n",
            "      \"bytes\": 251,\n",
            "      \"created_at\": 1732251651,\n",
            "      \"status\": \"processed\",\n",
            "      \"status_details\": null\n",
            "    },\n",
            "    {\n",
            "      \"object\": \"file\",\n",
            "      \"id\": \"file-IwxqKQpaAmWRESPZtoRF8SOF\",\n",
            "      \"purpose\": \"fine-tune\",\n",
            "      \"filename\": \"file\",\n",
            "      \"bytes\": 251,\n",
            "      \"created_at\": 1732250122,\n",
            "      \"status\": \"processed\",\n",
            "      \"status_details\": null\n",
            "    },\n",
            "    {\n",
            "      \"object\": \"file\",\n",
            "      \"id\": \"file-p976JiL9UKsYjbDTSlWBGPsF\",\n",
            "      \"purpose\": \"fine-tune-results\",\n",
            "      \"filename\": \"step_metrics.csv\",\n",
            "      \"bytes\": 1968,\n",
            "      \"created_at\": 1731891826,\n",
            "      \"status\": \"processed\",\n",
            "      \"status_details\": null\n",
            "    },\n",
            "    {\n",
            "      \"object\": \"file\",\n",
            "      \"id\": \"file-wbLAsY9VjJdBTcVV9UbtnnhI\",\n",
            "      \"purpose\": \"fine-tune\",\n",
            "      \"filename\": \"file\",\n",
            "      \"bytes\": 3128,\n",
            "      \"created_at\": 1731891511,\n",
            "      \"status\": \"processed\",\n",
            "      \"status_details\": null\n",
            "    },\n",
            "    {\n",
            "      \"object\": \"file\",\n",
            "      \"id\": \"file-lKwZOBqEWfzfLpyIlZGxIMkS\",\n",
            "      \"purpose\": \"fine-tune-results\",\n",
            "      \"filename\": \"step_metrics.csv\",\n",
            "      \"bytes\": 1940,\n",
            "      \"created_at\": 1731293594,\n",
            "      \"status\": \"processed\",\n",
            "      \"status_details\": null\n",
            "    },\n",
            "    {\n",
            "      \"object\": \"file\",\n",
            "      \"id\": \"file-yW1JpnLJJWPuUX8EDYfxmBVW\",\n",
            "      \"purpose\": \"fine-tune\",\n",
            "      \"filename\": \"file\",\n",
            "      \"bytes\": 3128,\n",
            "      \"created_at\": 1731293127,\n",
            "      \"status\": \"processed\",\n",
            "      \"status_details\": null\n",
            "    }\n",
            "  ],\n",
            "  \"has_more\": false,\n",
            "  \"first_id\": \"file-Xt0Jf7UuRLAv0w6U8jzNSQRP\",\n",
            "  \"last_id\": \"file-yW1JpnLJJWPuUX8EDYfxmBVW\"\n",
            "}\n",
            "Retrieve Response\n",
            "{\n",
            "  \"object\": \"file\",\n",
            "  \"id\": \"file-Xt0Jf7UuRLAv0w6U8jzNSQRP\",\n",
            "  \"purpose\": \"fine-tune\",\n",
            "  \"filename\": \"file\",\n",
            "  \"bytes\": 251,\n",
            "  \"created_at\": 1732252732,\n",
            "  \"status\": \"processed\",\n",
            "  \"status_details\": null\n",
            "}\n",
            "Delete Response\n",
            "{\n",
            "  \"object\": \"file\",\n",
            "  \"deleted\": true,\n",
            "  \"id\": \"file-Xt0Jf7UuRLAv0w6U8jzNSQRP\"\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Audio"
      ],
      "metadata": {
        "id": "yg_GccjnT3ec"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Function to transcribe audio using OpenAI Audio API\n",
        "def transcribe_audio(file_path, model = \"whisper-1\", response_format=\"json\", temperature=0.1, language=None, prompt=None):\n",
        "  with open(file_path, \"rb\") as audio_file:\n",
        "    response = openai.Audio.transcribe(\n",
        "        file=audio_file,\n",
        "        model = model,\n",
        "        response_format = response_format,\n",
        "        temperature=temperature,\n",
        "        language=language,\n",
        "        prompt=prompt\n",
        "    )\n",
        "    return response"
      ],
      "metadata": {
        "id": "TK3E2xKX6qZQ"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Example file path\n",
        "file_path = 'Dracula.mp3'\n",
        "\n",
        "#Transcribe the audio file\n",
        "transcription = transcribe_audio(file_path)\n",
        "print(\"Transcribe Response : \")\n",
        "print(transcription)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NUOOaeyi7W3e",
        "outputId": "d0a3cb29-ae62-4f0b-d321-7b6fff884b15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcribe Response : \n",
            "{\n",
            "  \"text\": \"Now that we've found where the enemy's lurking, nothing can stand in our way. Since we are facing the forces of darkness, we must be the cold light of day. We are the lanterns that burn in the lighthouse. The candles in the crypt. We are the light. Let there be light. This is a war and we must be the victors. There's too much to lose if we fail. We'll cross the seas like a band of crusaders searching for some precious grail. We are the embers that glow in the winter. The diamonds in the mine. Let's take our torches and pray God will show us a sign. Deep in the darkness night, when there's a spark of hope, we must be voice of light. He's in the darkness, bright as the dazzling stars in a different sky. And in our cruelest hour, when hope is gone, we'll raise our heads and we'll turn the odds. When the great battle commences, surely the light will prevail. We will break down his defenses. He will fall. And the sun will rise. Deep in the darkness night, when there's a spark of hope, we must be voice of light. He's in the darkness, bright as the dazzling stars in a different sky. And in our cruelest hour, when hope is gone, we'll raise our heads and we'll turn the odds.\"\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bXQ67BSs7kpT"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOClVyqk9LWqgYzjy7D0s2S",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}